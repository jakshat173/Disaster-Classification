{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n'''for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n'''\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport tensorflow as tf\nimport keras\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, Input\nfrom tensorflow.keras.applications import VGG16, Xception, VGG19, ResNet50, ResNet101, InceptionV3, InceptionResNetV2, MobileNetV2, DenseNet121, DenseNet169, EfficientNetB0, EfficientNetB7\nfrom keras.utils import to_categorical\nimport pickle\nimport joblib\nimport requests, time, urllib","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('../input/disaster-images-dataset-cnn-model/DisasterModel/train')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(os.listdir('../input/disaster-images-dataset-cnn-model/DisasterModel/Cyclone_Wildfire_Flood_Earthquake_Dataset/Flood'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total = 0\nsums = []\nfor i in range(len(os.listdir('../input/disaster-images-dataset-cnn-model/DisasterModel/Cyclone_Wildfire_Flood_Earthquake_Dataset'))):\n    #print(os.listdir('../input/disaster-images-dataset-cnn-model/DisasterModel/Cyclone_Wildfire_Flood_Earthquake_Dataset')[i])\n    path = '../input/disaster-images-dataset-cnn-model/DisasterModel/Cyclone_Wildfire_Flood_Earthquake_Dataset'\n    folder_path = path + '/' + os.listdir('../input/disaster-images-dataset-cnn-model/DisasterModel/Cyclone_Wildfire_Flood_Earthquake_Dataset')[i]\n    print(folder_path)\n    if folder_path != '../input/disaster-images-dataset-cnn-model/DisasterModel/Cyclone_Wildfire_Flood_Earthquake_Dataset/readme.txt':\n        sums.append(len(os.listdir(folder_path)))\n        total += len(os.listdir(folder_path))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('../input/disaster-images-dataset-cnn-model/DisasterModel/Cyclone_Wildfire_Flood_Earthquake_Dataset/readme.txt', 'r') as f:\n    print(f.read())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sums","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('../input/disaster-images-dataset-cnn-model/DisasterModel/Cyclone_Wildfire_Flood_Earthquake_Dataset')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From Here We're starting to add more images.","metadata":{}},{"cell_type":"code","source":"'''wildfire_url = ['https://unsplash.com/napi/search?query=fire&per_page=1000&xp=',\n               'https://unsplash.com/napi/search?query=forestfire&per_page=1000&xp=',\n               'https://unsplash.com/napi/search?query=fire&per_page=100&xp=',\n               'https://www.gettyimages.in/photos/wildfire?license=rf%2Crm&page=1&phrase=wildfire&recency=anydate&servicecontext=srp-autosuggest&sort=mostpopular',\n               'https://www.gettyimages.in/photos/forest-fire?license=rf%2Crm&page=1&phrase=forest%20fire&recency=anydate&servicecontext=srp-autosuggest&sort=mostpopular']\n\ncyclone_url = ['https://www.google.com/complete/search?q&cp=0&client=img&xssi=t&gs_ri=gws-wiz-img&ds=i&hl=en&authuser=0&pq=cyclone%20images&psi=0JdTYPjOC4i13LUPpfKsmAI.1616090933193',\n              'https://www.gettyimages.in/photos/cyclone?license=rf%2Crm&page=1&phrase=cyclone&recency=anydate&sort=mostpopular&suppressfamilycorrection=true&suppressphrasecorrection=true',\n              'https://www.gettyimages.in/photos/cyclone-australia?license=rf%2Crm&page=1&phrase=cyclone%20australia&recency=anydate&sort=mostpopular&suppressfamilycorrection=true&suppressphrasecorrection=true',\n              'https://www.google.com/complete/search?q&cp=0&client=img&xssi=t&gs_ri=gws-wiz-img&ds=i&hl=en&authuser=0&pq=cyclone%20images%20hd&psi=kptTYK33EcuLrtoP07O6uAU.1616091894521']\n\nearthquake_url = ['https://unsplash.com/napi/search?query=earthquake&per_page=1000&xp=',\n                 'https://unsplash.com/napi/search?query=earthquake%20damage&per_page=1000&xp=',\n                 'https://www.google.com/complete/search?q&cp=0&client=img&xssi=t&gs_ri=gws-wiz-img&ds=i&hl=en&authuser=0&pq=earthquake%20images&psi=9ZlTYO3CH5irrtoPxf6S4AY.1616091483048',\n                 'https://www.google.com/complete/search?q&cp=0&client=img&xssi=t&gs_ri=gws-wiz-img&ds=i&hl=en&authuser=0&pq=earthquake%20images&psi=QJpTYPDsOomprQGMkYZ4.1616091557797',\n                 'https://www.google.com/complete/search?q&cp=0&client=img&xssi=t&gs_ri=gws-wiz-img&ds=i&hl=en&authuser=0&pq=earthquake%20images&psi=XZpTYL6dDcyerAGp5pdo.1616091586460',\n                 'https://www.gettyimages.in/photos/earthquake-damage?license=rf%2Crm&page=1&phrase=earthquake%20damage&recency=anydate&sort=mostpopular&suppressfamilycorrection=true&suppressphrasecorrection=true']\n\nflood_url = ['https://www.google.com/complete/search?q&cp=0&client=img&xssi=t&gs_ri=gws-wiz-img&ds=i&hl=en&authuser=0&pq=flood%20images%2000hd&psi=7JtTYPuYMNG9yAPByLBA.1616091985086',\n            'https://www.google.com/complete/search?q&cp=0&client=img&xssi=t&gs_ri=gws-wiz-img&ds=i&hl=en&authuser=0&pq=flood%20images%2000hd&psi=E5xTYLvtG-W9rtoP4u-jwAI.1616092023933',\n            'https://www.google.com/complete/search?q&cp=0&client=img&xssi=t&gs_ri=gws-wiz-img&ds=i&hl=en&authuser=0&pq=flood%20images%2000hd&psi=M5xTYL-SHdG9yAPByLBA.1616092055987',\n            'https://unsplash.com/napi/search?query=flood&per_page=20&xp=',\n            'https://unsplash.com/napi/search?query=flooding&per_page=20&xp='] '''","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('../input/disaster-images-dataset-cnn-model/DisasterModel/train')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = []\nvalidation_images = []\ntrain_labels = []\nvalidation_labels = []\ntrain_size = 0.85\nvalidation_size = 0.15\nadditional_images = '../input/disaster-images-dataset-cnn-model/DisasterModel/Cyclone_Wildfire_Flood_Earthquake_Dataset'\nfor i in range(len(os.listdir(additional_images))):\n    print(os.listdir(additional_images)[i])\n    resulting_path = os.path.join(additional_images, os.listdir(additional_images)[i])\n    if not resulting_path.endswith('.txt'):\n        for j in range(len(os.listdir(resulting_path))):\n            #print(os.listdir(additional_images)[i], j)\n            if j < int(len(os.listdir(resulting_path))*0.85):\n                img_path = os.path.join(resulting_path, os.listdir(resulting_path)[j])\n                img = cv2.imread(img_path)\n                img = cv2.resize(img, (224, 224))\n                train_images.append(img/255)\n                train_labels.append(os.listdir(additional_images)[i])\n            else:\n                img_path = os.path.join(resulting_path, os.listdir(resulting_path)[j])\n                img = cv2.imread(img_path)\n                img = cv2.resize(img, (224, 224))\n                validation_images.append(img/255)\n                validation_labels.append(os.listdir(additional_images)[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Training images set length: ', len(train_images))\nprint('Validation images set length: ', len(validation_images))\nprint('Training Labels set length: ', len(train_labels))\nprint('Validation Labels set length: ', len(validation_labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = np.array(train_images)\nvalidation_images = np.array(validation_images)\ntrain_labels = np.array(train_labels)\nvalidation_labels = np.array(validation_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_images.shape)\nprint(train_labels.shape)\nprint(validation_images.shape)\nprint(validation_labels.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''train_path = '../input/disaster-images-dataset-cnn-model/DisasterModel/train'\ntest_path = '../input/disaster-images-dataset-cnn-model/DisasterModel/test'\nvalidation_path = '../input/disaster-images-dataset-cnn-model/DisasterModel/validation'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''os.listdir(train_path)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''train_images = []\ntrain_labels = []\nfor i in range(len(os.listdir(train_path))):\n    print(os.listdir(train_path)[i])\n    images_folder = train_path + '/' + os.listdir(train_path)[i]\n    for j in range(len(os.listdir(images_folder))):\n        train_labels.append(os.listdir(train_path)[i])\n        full_path = images_folder + '/' + os.listdir(images_folder)[j]\n        img = cv2.imread(full_path)\n        img = cv2.resize(img, (224, 224))\n        train_images.append(img/255)\n        print(i, j)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''train_images = np.array(train_images)\ntrain_labels = np.array(train_labels)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''train_images.shape'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''test_images = []\ntest_labels = []\nfor i in range(len(os.listdir(test_path))):\n    print(os.listdir(test_path)[i])\n    images_folder = test_path + '/' + os.listdir(test_path)[i]\n    for j in range(len(os.listdir(images_folder))):\n        test_labels.append(os.listdir(test_path)[i])\n        full_path = images_folder + '/' + os.listdir(images_folder)[j]\n        img = cv2.imread(full_path)\n        img = cv2.resize(img, (224, 224))\n        test_images.append(img/255)\n        print(i, j)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''test_images = np.array(test_images)\ntest_labels = np.array(test_labels)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''test_images.shape'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''validation_images = []\nvalidation_labels = []\nfor i in range(len(os.listdir(validation_path))):\n    print(os.listdir(validation_path)[i])\n    images_folder = validation_path + '/' + os.listdir(validation_path)[i]\n    for j in range(len(os.listdir(images_folder))):\n        validation_labels.append(os.listdir(validation_path)[i])\n        full_path = images_folder + '/' + os.listdir(images_folder)[j]\n        img = cv2.imread(full_path)\n        img = cv2.resize(img, (224, 224))\n        validation_images.append(img/255)\n        print(i, j)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''validation_images = np.array(validation_images)\nvalidation_labels = np.array(validation_labels)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''validation_images.shape'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer\nle = LabelEncoder()\nleb = LabelBinarizer()\ntrain_labels = leb.fit_transform(train_labels)\n#test_labels = leb.transform(test_labels)\nvalidation_labels = leb.transform(validation_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# BEFORE CONVERSION: \n# Flood -> 0\n# Cyclone -> 1\n# Wildfire -> 2\n# Earthquake -> 3\n#===========================\ntrain_labels\n# AFTER CONVERSION:\n# Flood -> 2\n# Cyclone -> 0\n# Wildfire -> 3\n# Earthquake -> 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''train_labels = to_categorical(train_labels)\nvalidation_labels = to_categorical(validation_labels)\ntest_labels = to_categorical(test_labels)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseModel = tf.keras.applications.DenseNet121(\n    include_top=False,\n    weights=\"imagenet\",\n    input_tensor=Input(shape=(224, 224, 3)),\n    input_shape=None,\n    pooling=None,\n    classes=4\n)\n#baseModel = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\nheadModel = baseModel.output\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dense(500, activation=\"relu\")(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(4, activation=\"softmax\")(headModel)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in baseModel.layers:\n    layer.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(inputs=baseModel.input, outputs=headModel)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer = 'Adam',\n    loss = 'categorical_crossentropy',\n    metrics = ['accuracy']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_images, train_labels, epochs = 30, batch_size = 100, validation_data=(validation_images, validation_labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\npred = model.predict(validation_images)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_model = []\npred_real = []\nfor i in range(len(pred)):\n    pred_model.append(np.argmax(pred[i]))\n    pred_real.append(np.argmax(validation_labels[i]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(np.array(pred_real), return_counts=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Confusion Matrix: ', confusion_matrix(pred_real, pred_model))\nprint('Accuracy_score: ', accuracy_score(pred_real, pred_model))\nprint('f1_score: ', f1_score(pred_real, pred_model, average='weighted'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_weights('model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.models.save_model(model, 'model_hdf5_one.hdf5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pickle.dumps(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"joblib.dump(model, 'pickled.pkl')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaded = pickle.loads('./pickled_model')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}